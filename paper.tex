\documentclass{sig-alternate}
\usepackage{color}


%%%% User-defined macros
\newcommand{\lam}{\lambda}
\newcommand{\mycomment}[1]{\textcolor{red}{#1}}
%%%%% Uncomment the following line and comment out the previous one
%%%%% to remove all comments
%%%%% NOTE: comments still occupy a line even if invisible;
%%%%% Don't write them as a separate paragraph
%\newcommand{\mycomment}[1]{}

\begin{document}

% --- Author Metadata here ---
%%% REMEMBER TO CHANGE THE SEMESTER AND YEAR
\conferenceinfo{UMM CSci Senior Seminar Conference, December 2013}{Morris, MN}

\title{Intrusion Detection with Genetic Algorithms and Fuzzy Logic}

\numberofauthors{1}

\author{
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
\alignauthor
Emma Ireland\\
	\affaddr{Division of Science and Mathematics}\\
	\affaddr{University of Minnesota, Morris}\\
	\affaddr{Morris, Minnesota, USA 56267}\\
	\email{irela065@morris.umn.edu}
}

\maketitle
\begin{abstract}

\end{abstract}

% A category with the (minimum) three required fields
\category{}{Security and Privacy}{Intrusion Detection Systems}

\terms{}

\keywords{Intrusion detection, genetic algorithm, fuzzy logic}

\section{Introduction}





\section{Background}

\subsection{Types of Intrusion Detection Systems}
There are two types of intrusion detection systems: \emph{host based} and \emph{network based}. Host based intrusion detection systems look at and analyze information that is on a single host or multiple host systems, such as the contents of file systems and system calls to determine if there is a possible threat to the system. Network based intrusion detection looks at information that is from the network. Network based is useful for analyzing the traffic of multiple systems all at once. This type of intrusion detection system analyzes packets that travel through the network.~\cite{DBLP:journals/corr/abs-1204-1336}




\subsection{Types of Networking Attacks}
There are four different types of networking attacks: \emph{denial of service}, \emph{remote to user attacks}, \emph{user to root attacks}, and \emph{probing}. Each attack that happens on a network can be placed into one of these categories. 

Denial of service attacks happen when an attacker makes a machine inaccessible to a user by making it too busy to serve legitimate network requests. Remote to user attacks happen when an attacker sends packets to a machine over the network in order to get access to things a local user would have on the machine. User to root attacks happen when an attacker starts out with access on the machine and then tries to gain root access to the system. Probing happens when an attacker examines a machine in order to collect information about weaknesses or vulnerabilities that in the future could be used in such a way that they compromise the system.~\cite{DBLP:journals/corr/abs-1204-1336}




\subsection{Detection Methodologies}
There are two different ways of detecting attacks: \emph{signature-based detection} and \emph{anomaly-based detection}. 

A signature is a pattern that corresponds to a known attack. Signature-based detection compares well-known patterns of attacks that are already in the intrusion detection system against captured events in order to identify a possible attack. It is a simple and effective way to detect known attacks. A disadvantage of it is that it is an ineffective way of detecting unknown attacks. Signature-based detection is also called \emph{knowledge-based detection} or \emph{misuse detection}.~\cite{Liao201316}

An anomaly is something that deviates from what is normal. Anomaly-based detection looks for patterns of activity that are rare and uncommon. It is an effective way to detect new vulnerabilities. Some disadvantages of this type of system is that they are expensive and they can detect an intrusive behavior as being normal because of insufficient data. Anomaly-based detection is also called \emph{behavior-based detection}.~\cite{DBLP:journals/corr/abs-1204-1336}




\subsection{False Positives and False Negatives}
\emph{False positives} and {False negatives} are two values that are used to evaluate the accuracy of an intrusion detection system. A false positive happens when an intrusion detection system incorrectly identifies normal activity as being an attack. A false negative happens when an intrusion detection system fails to identify harmful activity.~\cite{Liao201316}




\subsection{Genetic Algorithm}

\subsection{Fuzzy Logic}

\subsection{KDD99 Data Set}





\section{Fuzzy Genetic Algorithm Implementation}
The focus of the research is on detecting new or unknown types of attacks in a network. The intrusion detection system is able to identify normal network activity as well as classify different attack types using a fuzzy genetic algorithm. This kind of algorithm is able to learn new attacks, and has a high detection rate. The system used is evaluated in terms of detection speed, detection rate, and false alarm rate.




\subsection{RLD09 Data Set}
The KDD99 data set is 14 years old, and newer attack types are not included in it because of its age. Because of this, the authors of~\cite{6496342, 6559603} created their own data set, RLD09. To create the data set, the authors captured network data from the Computer Engineering Department at King Mongkut's University of Technology Thonburi, in Bangkok, Thailand. The data has around ten million preprocessed data packets. It has 17 different types of attacks, as well as normal network activity. The attacks can be divided into denial of service attacks and probe attacks. A packet sniffer was used to get information about TCP, UDP, and ICMP headers from protocol packets. Then this information is processed into 12 features by counting connections between a source IP and destination IP. Some example features include the number of: packets, source ports, and destination ports. The following are examples of data records, where each one has 12 feature values.

\begin{itemize}
\item 21,21,15,0,21,0,0,0,0,0,0,0, attack
\item 102,2,2,0,0,1,102,0,0,0,0,0, normal
\end{itemize}




\subsection{Algorithm Overview}
The algorithm that is used in~\cite{6496342, 6559603} first randomly finds a rule. Then the rule is improved in the training phase. After that, the rules are used to classify the data into classes in the testing phase. The pseudo code below describes the fuzzy genetic algorithm that is used. 

\mycomment{Ask Nic how to put in algorithm.}

The fitness function to be maximized is:
\begin{equation*}
fitness function = \frac{\alpha}{A} - \frac{\beta}{B}
\end{equation*}
In the implementation, a population size of 10 was used for each generation. An individual in the population represents a possible detection rule. The two best individuals from a present generation are preserved for the next generation. The other individuals in the new generation come from single-point crossover.



In order to measure the probability of an attack, a trapezoidal shape was used in the algorithm. The trapezoidal shape has four parameters: a, b, c, and d. The following algorithm calculates the probability of being attacked:

\mycomment{Ask Nic how to put in algorithm.}

\mycomment{Put in trapezoidal shape figure.}




\subsection{Features and Rules}
The KDD99 data set is composed of 41 features. The authors of~\cite{6496342, 6559603} used the following eight features in their system: duration, src\_bytes, num\_failed\_logins, root\_shell, num\_access\_files, srv\_count, serror\_rate, same\_srv\_rate.

\mycomment{Explain the 8 features}

The value of each feature is normalized to be a number between 0.0 and 7.0, and then is encoded into blocks of binary strings. See Figure~\ref{fig:fuzEncodingForFeature} for an example of a block. A rule has 12 blocks of features, and at the end of the string is the type of attack. 

\begin{figure}
\centering
\caption{Fuzzy encoding for a feature}
\begin{tabular}{|c|c|c|c|} \hline
010 & 011 & 100 & 101\\
a & b & c & d\\
\hline\end{tabular}
\label{fig:fuzEncodingForFeature}
\end{figure}

One record is passed into a rule. Each feature in a record is matched to one block of the rule. The parameters of each block measure the probability of an attack using the trapezoidal fuzzy rule shape. The probabilities of each block are then combined, and the average of the probabilities is compared with a threshold to determine if the record is an attack class or normal class. Then the predicted result is compared with the actual result.




\subsection{Experimental Design and Results}
\subsubsection{Experiments using Only RLD09}
The experiments that the authors of~\cite{6496342, 6559603} performed used a total of 16,000 records of normal activity and 10,500 records of attack activity. Of the attack activity, 4,000 of them were denial of service attacks and 6,500 were probe attacks.

In the first experiment, the fuzzy genetic algorithm was used to create denial of service and probe detection rules and then the rules were verified with known attack types. 10,000 records were used for the training set and all 26,500 records were used for the testing set. The two steps in the training process were to find a denial of service rule, and find a probe rule from the training set. Both of these rules were then used in the testing process to identify attacks from the testing data set. The following algorithm was used in the testing process:

\mycomment{Ask Nic how to put in algorithm.}

The detection rate of denial of service attacks in training was 91.64\% and the detection rate of probe attacks in training was 94.79\%. The detection rate of the testing data set increased to 97.92\%. The false positive rate was 1.13\% and the false negative rate was 4.10\%. Detection of an attack happened 2-3 seconds after the packet data arrived at the intrusion detection system. Results from this experiment are shown in Table~\ref{tab:fuzGenExp1}.

\mycomment{Fix table}

\begin{table}
\caption{Results from Experiment 1}
\begin{tabular}{|ccccccc|} \hline
 & Attack & Normal & Total Records & FP & FN & DR\\
DoS Training & 1499 & 8501 & 10000 & 1.46 & 47.50 & 91.64\\
Probe Training & 2496 & 7504 & 10000 & 1.83 & 15.38 & 94.79\\
Testing & 10500 & 1600 & 26500 & 1.13 & 4.10 & 97.92\\
\hline\end{tabular}
\label{tab:fuzGenExp1}
\end{table}

In the second experiment, seven tests were run. For each test case there were 13 attack types plus normal activity that were in the training data set. Three attack types were used for the unknown testing data set. For example, the first test case used the training data set that does not have Advance Port Scan, Ack Scan, and Xmas Tree, (which are all probe attacks). These three attacks were then used for the testing data set. Table~\ref{tab:fuzGenExp2} shows some of the results from the fuzzy genetic algorithm and a decision tree algorithm. The fuzzy genetic algorithm has an accuracy of at least 95\% in identifying unknown attacks. When compared with the decision tree algorithm, the fuzzy genetic algorithm has a higher detection rate in all cases except 3 and 5. It can be seen that in cases 2 and 4 the decision tree has low detection rates, while the fuzzy genetic algorithm has much higher detection rates.


\begin{table}
\caption{Unknown Attack Experiment}
\begin{tabular}{|lllcrl|} \hline
Test & Unknown & Decision & & Fuzzy & \\
Case & Attacks & Tree DR & & Genetic DR & \\ \hline

1 & Advance Port Scan & 99.7 & Avg = & 100 & Avg =\\
  & Ack Scan          & 100  & 98.33 & 100 & 100\\
  & Xmas Tree         & 95.3 &       & 100 &\\ \hline

2 & UDP Flood & \textbf{26.7} & Avg = & \textbf{100} & Avg =\\
  & Host Scan & 98.15         & 46.65 & 99.20        & 99.80\\
  & UDP Scan  & \textbf{17.6} &       & \textbf{100} &\\ \hline

3 & Jping    & 100 & Avg =          & 99.20 & Avg =\\
  & Syn Scan & 99.1& \textbf{99.70} & 96.60 & 98.75\\
  & Fin Scan & 100 &                & 100 &\\ \hline

4 & UDP Flood & \textbf{26.6} & Avg = & \textbf{100} & Avg =\\
  & RCP Scan  & 91.56         & 70.35 & 92.60        & 98.15\\
  & Fin Scan  & 99.8          &       & 100          &\\ \hline

5 & Http Flood & 85.7& Avg =          & 100 & Avg =\\
  & RCP Scan  & 92.3 & \textbf{99.94} & 91.80 & 97.50\\
  & Fin Scan  & 99.8 &                & 98.20 &\\
  
\hline\end{tabular}
\label{tab:fuzGenExp2}
\end{table}



\subsubsection{Experiments using Both RLD09 and KDD99}
The authors of~\cite{6496342, 6559603} also ran experiments that compared the RLD09 data set with the KDD99 data set. They used the KDD99 10\% version file for both the training dataset and testing dataset. The number of records of normal and attack activity for the two data sets are shown in Table~\ref{tab:RecordsForKDD99}.

\begin{table}
\caption{Number of Records for KDD99}
\begin{tabular}{|lll|} \hline
Attack & Training & Testing\\
Type   & Data set & Data set\\ \hline
Normal & 39,387 & 39,337\\
DoS & 158,597 & 158,503\\
Probe & 1,550 & 1,674\\
 & &\\
 Total & 199,534 & 199,514\\

\hline\end{tabular}
\label{tab:RecordsForKDD99}
\end{table}



\section{Genetic Algorithm Implementation}

\subsection{Algorithm Overview}

\subsection{Experimental Design and Results}





\section{Conclusions}





\section{Acknowledgments}




% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
% sample_paper.bib is the name of the BibTex file containing the
% bibliography entries. Note that you *don't* include the .bib ending here.
\bibliography{annotated_bibliography}  
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references

\end{document}
